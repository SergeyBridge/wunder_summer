{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curdir: /home/sergey/mnt/st1500/Usr/Sergey/TheJob/Challenges/wunder_summer/wunder_challenge/examples/catboost_local\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lg\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# from importlib import reload\n",
    "\n",
    "\n",
    "import catboost\n",
    "from catboost.utils import get_gpu_device_count\n",
    "\n",
    "sys.path.append(\"../../scorer/\")\n",
    "import orderbook_fast as ob\n",
    "\n",
    "# from  solution import get_simple_features_from_orderbook, get_simple_deals_features\n",
    "# from  solution import get_simple_deals_features\n",
    "\n",
    "from my_orderbook import MyOrderBook, action_handler\n",
    "catboost_myob = MyOrderBook()\n",
    "\n",
    "SIDE_BID = 0 \n",
    "SIDE_ASK = 1\n",
    "\n",
    "print(f\"curdir: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Собираем датасет для тренировки модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "collecting dataset: 100%|██████████| 31735888/31735888 [3:18:13<00:00, 2668.35it/s]  \n",
      "collecting dataset:  12%|█▏        | 1284792/10617618 [08:09<1:25:45, 1813.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset collected: len(X) = 706531\n"
     ]
    }
   ],
   "source": [
    "def collect_dataset(data_path):\n",
    "    '''\n",
    "        Собираем датасет\n",
    "    '''\n",
    "\n",
    "    global catboost_myob\n",
    "    event_player = ob.EventPlayer(data_path)\n",
    "    orderbook = ob.OrderBook()\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for ev in tqdm(event_player.iget_events(),\n",
    "                    total=len(event_player),\n",
    "                    desc=\"collecting dataset\"):\n",
    "\n",
    "        catboost_myob.__getattribute__(action_handler[ev.action])\n",
    "\n",
    "        orderbook.apply_event(ev)\n",
    "        if ev.need_prediction:\n",
    "            features = catboost_myob.get_features(ev, orderbook)\n",
    "\n",
    "            X.append(features)\n",
    "            Y.append(ev.Y)\n",
    "\n",
    "    print(f\"Dataset collected: len(X) = {len(X)}\")\n",
    "    return pd.DataFrame(X), pd.DataFrame(Y)\n",
    "\n",
    "\n",
    "# X_train, Y_train = collect_dataset(\"../../data/very_small_A.npz\")\n",
    "# X_test, Y_test = collect_dataset(\"../../data/very_small_B.npz\")\n",
    "\n",
    "# X_train_large, Y_train_large = collect_dataset(\"../../data/train.npz\")\n",
    "# X_train_large.to_pickle(\"X_train_large.pickle\")\n",
    "# Y_train_large.to_pickle(\"Y_train_large.pickle\")\n",
    "\n",
    "X_train80, Y_train80 = collect_dataset(\"../../data/train80.npz\")\n",
    "X_train80.to_pickle(\"X_train80.pickle\")\n",
    "Y_train80.to_pickle(\"Y_train80.pickle\")\n",
    "\n",
    "X_test20, Y_test20 = collect_dataset(\"../../data/test20.npz\")\n",
    "X_test20.to_pickle(\"X_test20.pickle\")\n",
    "Y_test20.to_pickle(\"Y_test20.pickle\")\n",
    "\n",
    "\n",
    "print(\"X_train.shape  == \", X_train80.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Обучаем модель градиентного бустинга"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "def train_catboost(X_train, Y_train, X_test, Y_test):\n",
    "\n",
    "    task_type = \"CPU\" #  if (get_gpu_device_count() == 0) else \"GPU\"\n",
    "    langevin = False if task_type == \"GPU\" else True\n",
    "    print(f\"catboost training with {task_type}...\")\n",
    "    print(\"X_train.shape = \", X_train.shape)\n",
    "    print(\"get_gpu_device_count() = \", get_gpu_device_count())\n",
    "\n",
    "    train_pool = catboost.Pool(X_train, Y_train, cat_features=catboost_myob.cat_features)     #    , cat_features=cat_features)\n",
    "\n",
    "    grid = {'learning_rate': [0.03],\n",
    "            # 'score_function': [\"Cosine\", \"L2\", \"NewtonL2\"],\n",
    "            'depth': [4, 5, 6],\n",
    "            'l2_leaf_reg': [2, 3, 5, 8, 11],\n",
    "            # 'nan_mode': [\"Min\", \"Max\"],\n",
    "            # 'fold_len_multiplier': np.linspace(1.1, 3, 3),\n",
    "            # 'bagging_temperature': np.linspace(1, 3000, 3),\n",
    "\n",
    "    }\n",
    "\n",
    "    model = catboost.CatBoostClassifier(\n",
    "\n",
    "        bootstrap_type=\"Bayesian\",\n",
    "        # scale_pos_weight=en.scale_pos_weight,\n",
    "        # scale_pos_weight=1,\n",
    "        loss_function = \"Logloss\",\n",
    "        eval_metric=\"AUC:hints=skip_train~false\",\n",
    "        langevin=langevin,\n",
    "        custom_metric=[\"Recall\", \"Precision\", \"Accuracy\", \"F1\", \"Kappa\", \"MCC\"],\n",
    "        # use_best_model=True,\n",
    "        iterations=5,\n",
    "        od_type=\"Iter\",\n",
    "        od_wait=30,\n",
    "        # rsm=0.5,\n",
    "        # random_seed=100,\n",
    "        task_type=task_type,\n",
    "        boosting_type='Ordered',\n",
    "        logging_level=\"Verbose\",\n",
    "        train_dir=\"grid\",\n",
    "\n",
    "    )\n",
    "\n",
    "    grid_search_result = model.grid_search(\n",
    "        grid,\n",
    "        X=train_pool,\n",
    "        stratified=True,\n",
    "        cv=3,\n",
    "        search_by_train_test_split=False,\n",
    "        plot=False      # PLOT,\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "    params = model.get_params()\n",
    "    for param in params.items():\n",
    "        print(param)\n",
    "\n",
    "    return grid_search_result, model\n",
    "\n",
    "grid_search_result, clf = train_catboost(X_train, Y_train, X_test, Y_test)\n",
    "# clf = train_classifier(X_train, Y_train, X_test, Y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестируем получившийся классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def process_event_and_predict_proba(event, orderbook):\n",
    "\n",
    "    catboost_myob.__getattribute__(action_handler[event.action])\n",
    "\n",
    "    if not event.need_prediction:\n",
    "        return None\n",
    "\n",
    "    features = catboost_myob.get_features(event, orderbook, max_index=13)\n",
    "\n",
    "    proba = clf.predict_proba([features])[0, 1]\n",
    "\n",
    "    return proba\n",
    "\n",
    "from scorer import Scorer\n",
    "\n",
    "# scoring = Scorer(\"../../data/train_small_C.npz\")\n",
    "scoring = Scorer(\"../../data/very_small_B.npz\")\n",
    "roc_auc, (true_ys, pred_probas) = scoring.score(process_event_and_predict_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохраним модель, и решение для отправки готово"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Сохраним нашу модель\n",
    "# clf.booster_.save_model(\"wunder.model\")\n",
    "clf.save_model(\"wunder.model\", format=\"cbm\")\n",
    "print(f\"curdir: {Path.cwd()}\")\n",
    "'''Посмотрите код файла solution.py. \n",
    "Он использует те же функции что и этот ноутбук, но уже готов к отправке на серверю. \n",
    "Попробуйте создать архив с файлами solution.py и wunder.model и отправить их на проверку.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}