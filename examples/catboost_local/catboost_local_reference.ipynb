{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import lightgbm as lg\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import catboost\n",
    "from catboost.utils import get_gpu_device_count\n",
    "\n",
    "sys.path.append(\"../../scorer/\")\n",
    "# import orderbook as ob\n",
    "# Чтобы использовать быстрый ордербук раскомментируйте строку:\n",
    "import orderbook_fast as ob\n",
    " \n",
    "SIDE_BID = 0 \n",
    "SIDE_ASK = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Собираем датасет для тренировки модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "collecting dataset: 100%|██████████| 10617618/10617618 [01:07<00:00, 157768.52it/s]\n",
      "collecting dataset: 100%|██████████| 10555835/10555835 [01:06<00:00, 157680.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset collected: len(X) = 234905\n",
      "Dataset collected: len(X) = 240309\n"
     ]
    }
   ],
   "source": [
    "def get_simple_features_from_orderbook(orderbook, max_index=2):\n",
    "    '''\n",
    "        Считаем простые фичи по ордербуку:\n",
    "    '''\n",
    "    spread = orderbook.get_best_price(SIDE_ASK) - orderbook.get_best_price(SIDE_BID)\n",
    "    features = [spread]\n",
    "    for side in (SIDE_BID, SIDE_ASK):\n",
    "        for ix in range(max_index):\n",
    "            price_level = orderbook.get_price_level_at_ix(side, ix)\n",
    "            if price_level is None:\n",
    "                features += [-1, -1]\n",
    "            else:\n",
    "                features += [price_level.get_volume(), \n",
    "                             price_level.get_num_orders()]\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_simple_deals_features(last_deals, orderbook):\n",
    "    '''\n",
    "        Считаем простые фичи по последним сделкам:\n",
    "    '''\n",
    "    cur_mean_price = orderbook.get_mean_price()\n",
    "    cur_time = orderbook.get_time()\n",
    "\n",
    "    features = []\n",
    "    for side in (SIDE_BID, SIDE_ASK):\n",
    "        deal_event = last_deals[side]\n",
    "        if deal_event is None:\n",
    "            features += [-1e9, -1e9, -1e9]\n",
    "        else:\n",
    "            features += [cur_mean_price - deal_event.price, \n",
    "                         cur_time - deal_event.time, \n",
    "                         deal_event.amount]\n",
    "    return features\n",
    "\n",
    "\n",
    "def collect_dataset(data_path):\n",
    "    '''\n",
    "        Собираем датасет\n",
    "    '''\n",
    "    event_player = ob.EventPlayer(data_path)\n",
    "    orderbook = ob.OrderBook()\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    last_deals = [None, None]\n",
    "    for ev in tqdm(event_player.iget_events(), \n",
    "                    total=len(event_player), \n",
    "                    desc=\"collecting dataset\"):\n",
    "        if ev.action == ob.Action.DEAL:\n",
    "            last_deals[ev.side] = ev\n",
    "        elif ev.action == ob.Action.NEW_CHUNK:\n",
    "            last_deals = [None, None]\n",
    "        \n",
    "        orderbook.apply_event(ev)\n",
    "        if ev.need_prediction:\n",
    "            features = get_simple_features_from_orderbook(orderbook)\n",
    "            features += get_simple_deals_features(last_deals, orderbook)\n",
    "\n",
    "            X.append(features)\n",
    "            Y.append(ev.Y)\n",
    "\n",
    "    print(f\"Dataset collected: len(X) = {len(X)}\")\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "\n",
    "X_train, Y_train = collect_dataset(\"../../data/train_small_A.npz\")\n",
    "X_test, Y_test = collect_dataset(\"../../data/train_small_B.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучаем модель градиентного бустинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_classifier(X_train, Y_train, X_test, Y_test):\n",
    "    '''\n",
    "        Обучаем классификатор\n",
    "    '''\n",
    "    clf = lg.LGBMClassifier(num_leaves=31, n_estimators=1000, learning_rate=0.1)\n",
    "    clf.fit(X_train, Y_train, eval_set=[(X_test, Y_test)], \n",
    "            eval_metric=\"auc\", early_stopping_rounds=20)\n",
    "    return clf\n",
    " \n",
    "# clf = train_classifier(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catboost training with CPU...\n",
      "X_train.shape =  (234905, 15)\n",
      "get_gpu_device_count() =  1\n",
      "0:\tloss: 0.6060353\tbest: 0.6060353 (0)\ttotal: 12.1s\tremaining: 5m 49s\n",
      "1:\tloss: 0.6060113\tbest: 0.6060353 (0)\ttotal: 23.2s\tremaining: 5m 25s\n",
      "2:\tloss: 0.6059978\tbest: 0.6060353 (0)\ttotal: 35.6s\tremaining: 5m 20s\n",
      "3:\tloss: 0.6059995\tbest: 0.6060353 (0)\ttotal: 47.2s\tremaining: 5m 6s\n",
      "4:\tloss: 0.6059811\tbest: 0.6060353 (0)\ttotal: 59.1s\tremaining: 4m 55s\n",
      "5:\tloss: 0.6059804\tbest: 0.6060353 (0)\ttotal: 1m 11s\tremaining: 4m 45s\n",
      "6:\tloss: 0.6059590\tbest: 0.6060353 (0)\ttotal: 1m 24s\tremaining: 4m 36s\n",
      "7:\tloss: 0.6059391\tbest: 0.6060353 (0)\ttotal: 1m 37s\tremaining: 4m 27s\n",
      "8:\tloss: 0.6057664\tbest: 0.6060353 (0)\ttotal: 1m 49s\tremaining: 4m 16s\n",
      "9:\tloss: 0.6058218\tbest: 0.6060353 (0)\ttotal: 2m 2s\tremaining: 4m 5s\n",
      "10:\tloss: 0.6076494\tbest: 0.6076494 (10)\ttotal: 2m 15s\tremaining: 3m 54s\n",
      "11:\tloss: 0.6066110\tbest: 0.6076494 (10)\ttotal: 2m 28s\tremaining: 3m 42s\n",
      "12:\tloss: 0.6076393\tbest: 0.6076494 (10)\ttotal: 2m 40s\tremaining: 3m 30s\n",
      "13:\tloss: 0.6055380\tbest: 0.6076494 (10)\ttotal: 2m 54s\tremaining: 3m 19s\n",
      "14:\tloss: 0.6068788\tbest: 0.6076494 (10)\ttotal: 3m 7s\tremaining: 3m 7s\n",
      "15:\tloss: 0.6051273\tbest: 0.6076494 (10)\ttotal: 3m 19s\tremaining: 2m 54s\n",
      "16:\tloss: 0.6058822\tbest: 0.6076494 (10)\ttotal: 3m 31s\tremaining: 2m 41s\n",
      "17:\tloss: 0.6048653\tbest: 0.6076494 (10)\ttotal: 3m 43s\tremaining: 2m 29s\n",
      "18:\tloss: 0.6059164\tbest: 0.6076494 (10)\ttotal: 3m 56s\tremaining: 2m 16s\n",
      "19:\tloss: 0.6043396\tbest: 0.6076494 (10)\ttotal: 4m 7s\tremaining: 2m 3s\n",
      "20:\tloss: 0.6050408\tbest: 0.6076494 (10)\ttotal: 4m 22s\tremaining: 1m 52s\n",
      "21:\tloss: 0.6058161\tbest: 0.6076494 (10)\ttotal: 4m 36s\tremaining: 1m 40s\n",
      "22:\tloss: 0.6049565\tbest: 0.6076494 (10)\ttotal: 4m 50s\tremaining: 1m 28s\n",
      "23:\tloss: 0.6058023\tbest: 0.6076494 (10)\ttotal: 5m 5s\tremaining: 1m 16s\n",
      "24:\tloss: 0.6047336\tbest: 0.6076494 (10)\ttotal: 5m 20s\tremaining: 1m 4s\n",
      "25:\tloss: 0.6057801\tbest: 0.6076494 (10)\ttotal: 5m 34s\tremaining: 51.5s\n",
      "26:\tloss: 0.6049604\tbest: 0.6076494 (10)\ttotal: 5m 49s\tremaining: 38.8s\n",
      "27:\tloss: 0.6053010\tbest: 0.6076494 (10)\ttotal: 6m 3s\tremaining: 26s\n",
      "28:\tloss: 0.6048528\tbest: 0.6076494 (10)\ttotal: 6m 17s\tremaining: 13s\n",
      "29:\tloss: 0.6054831\tbest: 0.6076494 (10)\ttotal: 6m 32s\tremaining: 0us\n",
      "('iterations', 10)\n",
      "('loss_function', 'Logloss')\n",
      "('od_wait', 30)\n",
      "('od_type', 'Iter')\n",
      "('logging_level', 'Verbose')\n",
      "('train_dir', 'grid')\n",
      "('custom_metric', ['Recall', 'Precision', 'Accuracy', 'F1', 'Kappa', 'MCC'])\n",
      "('eval_metric', 'AUC:hints=skip_train~false')\n",
      "('boosting_type', 'Ordered')\n",
      "('task_type', 'CPU')\n",
      "('bootstrap_type', 'Bayesian')\n",
      "('langevin', True)\n",
      "('depth', 5)\n",
      "('l2_leaf_reg', 2)\n",
      "('learning_rate', 0.03)\n",
      "CPU times: user 8min 30s, sys: 47.8 s, total: 9min 18s\n",
      "Wall time: 6min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def train_catboost(X_train, Y_train, X_test, Y_test):\n",
    "\n",
    "    task_type = \"CPU\" #  if (get_gpu_device_count() == 0) else \"GPU\"\n",
    "    langevin = False if task_type == \"GPU\" else True\n",
    "    print(f\"catboost training with {task_type}...\")\n",
    "    print(\"X_train.shape = \", X_train.shape)\n",
    "    print(\"get_gpu_device_count() = \", get_gpu_device_count())\n",
    "\n",
    "    train_pool = catboost.Pool(X_train, Y_train)\n",
    "\n",
    "    grid = {'learning_rate': [0.03, 0.01],\n",
    "            # 'score_function': [\"Cosine\", \"L2\", \"NewtonL2\"],\n",
    "            'depth': [4, 5, 6],\n",
    "            'l2_leaf_reg': [2, 3, 5, 8, 11],\n",
    "            # 'nan_mode': [\"Min\", \"Max\"],\n",
    "            # 'fold_len_multiplier': np.linspace(1.1, 3, 3),\n",
    "            # 'bagging_temperature': np.linspace(1, 3000, 3),\n",
    "\n",
    "    }\n",
    "\n",
    "    model = catboost.CatBoostClassifier(\n",
    "\n",
    "        bootstrap_type=\"Bayesian\",\n",
    "        # scale_pos_weight=en.scale_pos_weight,\n",
    "        # scale_pos_weight=1,\n",
    "        loss_function = \"Logloss\",\n",
    "        eval_metric=\"AUC:hints=skip_train~false\",\n",
    "        langevin=langevin,\n",
    "        custom_metric=[\"Recall\", \"Precision\", \"Accuracy\", \"F1\", \"Kappa\", \"MCC\"],\n",
    "        # use_best_model=True,\n",
    "        iterations=10,\n",
    "        od_type=\"Iter\",\n",
    "        od_wait=30,\n",
    "        # rsm=0.5,\n",
    "        # random_seed=100,\n",
    "        task_type=task_type,\n",
    "        boosting_type='Ordered',\n",
    "        logging_level=\"Verbose\",\n",
    "        train_dir=\"grid\",\n",
    "\n",
    "    )\n",
    "\n",
    "    grid_search_result = model.grid_search(\n",
    "        grid,\n",
    "        X=train_pool,\n",
    "        stratified=True,\n",
    "        cv=3,\n",
    "        search_by_train_test_split=False,\n",
    "        plot=False      # PLOT,\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "    params = model.get_params()\n",
    "    for param in params.items():\n",
    "        print(param)\n",
    "\n",
    "    return grid_search_result, model\n",
    "\n",
    "grid_search_result, clf = train_catboost(X_train, Y_train, X_test, Y_test)\n",
    "# clf = train_classifier(X_train, Y_train, X_test, Y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестируем получившийся классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "last_deals = [None, None]\n",
    "\n",
    "def process_event_and_predict_proba(event, orderbook):\n",
    "    if event.action == ob.Action.DEAL:\n",
    "        last_deals[event.side] = event\n",
    "    elif event.action == ob.Action.NEW_CHUNK:\n",
    "        last_deals[:] = [None, None]\n",
    "        \n",
    "    if not event.need_prediction:\n",
    "        return None\n",
    "    \n",
    "    features = get_simple_features_from_orderbook(orderbook)\n",
    "    features += get_simple_deals_features(last_deals, orderbook)    \n",
    "    proba = clf.predict_proba([features])[0, 1]\n",
    "    return proba\n",
    "\n",
    "from scorer import Scorer\n",
    "\n",
    "scoring = Scorer(\"../../data/train_small_C.npz\")\n",
    "# roc_auc, (true_ys, pred_probas) = scoring.score(process_event_and_predict_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохраним модель, и решение для отправки готово"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curdir: /home/sergey/mnt/st1500/Usr/Sergey/TheJob/Challenges/wunder_summer/wunder_challenge/examples/catboost\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Посмотрите код файла solution.py. \\nОн использует те же функции что и этот ноутбук, но уже готов к отправке на серверю. \\nПопробуйте создать архив с файлами solution.py и wunder.model и отправить их на проверку.'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сохраним нашу модель\n",
    "# clf.booster_.save_model(\"wunder.model\")\n",
    "clf.save_model(\"wunder.model\", format=\"cbm\")\n",
    "print(f\"curdir: {Path.cwd()}\")\n",
    "'''Посмотрите код файла solution.py. \n",
    "Он использует те же функции что и этот ноутбук, но уже готов к отправке на серверю. \n",
    "Попробуйте создать архив с файлами solution.py и wunder.model и отправить их на проверку.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}